version: '3.8'

services:
  # PostgreSQL for Orchestrator
  postgres:
    image: postgres:15-alpine
    environment:
      POSTGRES_DB: orchestrator
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres123
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 5s
      timeout: 5s
      retries: 5

  # MongoDB for Agent Manager
  mongodb:
    image: mongo:6.0
    environment:
      MONGO_INITDB_ROOT_USERNAME: admin
      MONGO_INITDB_ROOT_PASSWORD: mongo123
      MONGO_INITDB_DATABASE: agent_manager
    ports:
      - "27017:27017"
    volumes:
      - mongo_data:/data/db
    healthcheck:
      test: echo 'db.runCommand("ping").ok' | mongosh localhost:27017/test --quiet
      interval: 5s
      timeout: 5s
      retries: 5

  # Redis for caching and messaging
  redis:
    image: redis:7-alpine
    command: redis-server --requirepass redis123
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      interval: 5s
      timeout: 5s
      retries: 5

  # Temporal Server for workflow orchestration
  temporal:
    image: temporalio/auto-setup:1.22.4
    environment:
      - DB=postgresql
      - DB_PORT=5432
      - POSTGRES_USER=postgres
      - POSTGRES_PWD=postgres123
      - POSTGRES_SEEDS=postgres
    ports:
      - "7233:7233"
    depends_on:
      postgres:
        condition: service_healthy

  # Orchestrator Service
  orchestrator:
    build:
      context: ./services/orchestrator
      dockerfile: Dockerfile
    environment:
      - SERVER_PORT=8080
      - DB_HOST=postgres
      - DB_PORT=5432
      - DB_NAME=orchestrator
      - DB_USER=postgres
      - DB_PASSWORD=postgres123
      - ORCHESTRATOR_DATABASE_URL=postgres://postgres:postgres123@postgres:5432/orchestrator?sslmode=disable
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_PASSWORD=redis123
      - ORCHESTRATOR_REDIS_ADDR=redis:6379
      - ORCHESTRATOR_REDIS_PASSWORD=redis123
      - LOG_LEVEL=debug
      - ORCHESTRATOR_TELEMETRY_ENABLED=false
      - ORCHESTRATOR_TEMPORAL_HOST_PORT=temporal:7233
      - ORCHESTRATOR_AGENT_MANAGER_BASE_URL=http://agent-manager:8082
    ports:
      - "8080:8080"
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      temporal:
        condition: service_started
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Intent Processor Service
  intent-processor:
    build:
      context: ./services/intent-processor
      dockerfile: Dockerfile
    environment:
      - SERVER_PORT=8081
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_PASSWORD=redis123
      - AGENT_MANAGER_URL=http://agent-manager:8082
      - ORCHESTRATOR_URL=http://orchestrator:8080
      # LLM Provider Configuration
      - LLM_PROVIDER=${LLM_PROVIDER:-ollama}
      - LLM_MODEL=${LLM_MODEL:-mistral}
      - LLM_TEMPERATURE=0.7
      - LLM_MAX_TOKENS=2000
      # Ollama
      - OLLAMA_BASE_URL=${OLLAMA_BASE_URL:-https://model.gonella.co.uk}
      - USE_OLLAMA=${USE_OLLAMA:-true}
      # Groq
      - GROQ_API_KEY=${GROQ_API_KEY}
      # OpenAI
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      # Anthropic
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      # Azure OpenAI (fallback)
      - AZURE_OPENAI_API_KEY=${AZURE_OPENAI_API_KEY:-dummy-key}
      - AZURE_OPENAI_ENDPOINT=${AZURE_OPENAI_ENDPOINT:-https://dummy.openai.azure.com}
      - AZURE_OPENAI_DEPLOYMENT_NAME=${AZURE_OPENAI_DEPLOYMENT_NAME:-gpt-35-turbo}
      - LOG_LEVEL=debug
    ports:
      - "8081:8081"
    depends_on:
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8081/health"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Agent Manager Service
  agent-manager:
    build:
      context: ./services/agent-manager
      dockerfile: Dockerfile
    environment:
      - PORT=8082
      - NODE_ENV=development
      - MONGO_URI=mongodb://admin:mongo123@mongodb:27017/agent_manager?authSource=admin
      - MONGODB_URI=mongodb://admin:mongo123@mongodb:27017/agent_manager?authSource=admin
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_PASSWORD=redis123
      - REDIS_URL=redis://:redis123@redis:6379
      - LOG_LEVEL=debug
      - AZURE_TENANT_ID=dummy-tenant-id
      - AZURE_CLIENT_ID=dummy-client-id
      - AZURE_CLIENT_SECRET=dummy-client-secret
    ports:
      - "8082:8082"
    depends_on:
      mongodb:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8082/health"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Code Generation Agent
  code-gen-agent:
    build:
      context: ./services/agents/code-gen-agent
      dockerfile: Dockerfile
    environment:
      - NODE_ENV=production
      - AGENT_MANAGER_URL=http://agent-manager:8082
      - AGENT_ID=code-gen-agent-001
      - LOG_LEVEL=info
    depends_on:
      agent-manager:
        condition: service_healthy
    restart: unless-stopped

  # Meta-Prompt Orchestrator for Dynamic Agents
  meta-prompt-agent:
    build:
      context: ./services/agents/meta-prompt-agent
      dockerfile: Dockerfile
    environment:
      - NODE_ENV=production
      - META_AGENT_ID=meta-prompt-orchestrator
      - AGENT_MANAGER_URL=http://agent-manager:8082
      # LLM Provider Configuration
      - LLM_PROVIDER=${LLM_PROVIDER:-ollama}
      - LLM_MODEL=${LLM_MODEL:-mistral}
      - LLM_TEMPERATURE=0.7
      - LLM_MAX_TOKENS=2000
      # Ollama
      - OLLAMA_BASE_URL=${OLLAMA_BASE_URL:-https://model.gonella.co.uk}
      - USE_OLLAMA=${USE_OLLAMA:-true}
      # Groq
      - GROQ_API_KEY=${GROQ_API_KEY}
      # OpenAI
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      # Anthropic
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      # Azure OpenAI (fallback)
      - AZURE_OPENAI_API_KEY=${AZURE_OPENAI_API_KEY:-dummy-key}
      - AZURE_OPENAI_INSTANCE_NAME=${AZURE_OPENAI_INSTANCE_NAME:-dummy-instance}
      - AZURE_OPENAI_DEPLOYMENT_NAME=${AZURE_OPENAI_DEPLOYMENT_NAME:-gpt-35-turbo}
      - AZURE_OPENAI_API_VERSION=2023-05-15
      - REDIS_URL=redis://:redis123@redis:6379
      - LOG_LEVEL=info
    depends_on:
      agent-manager:
        condition: service_healthy
      redis:
        condition: service_healthy
    restart: unless-stopped

volumes:
  postgres_data:
  mongo_data:
  redis_data:

networks:
  default:
    name: qlp-minimal
