# LLM Provider Configuration
# Uncomment and configure the provider you want to use

# Ollama (Local or Remote)
OLLAMA_BASE_URL=https://model.gonella.co.uk
OLLAMA_MODEL=mistral

# Groq (Fast Inference)
# GROQ_API_KEY=your-groq-api-key
# GROQ_MODEL=mixtral-8x7b-32768

# OpenAI
# OPENAI_API_KEY=your-openai-api-key
# OPENAI_MODEL=gpt-4

# Anthropic Claude
# ANTHROPIC_API_KEY=your-anthropic-api-key
# ANTHROPIC_MODEL=claude-3-opus-20240229

# Azure OpenAI (Legacy)
AZURE_OPENAI_API_KEY=dummy-key
AZURE_OPENAI_ENDPOINT=https://dummy.openai.azure.com
AZURE_OPENAI_DEPLOYMENT_NAME=gpt-35-turbo

# Service Configuration
NODE_ENV=development
LOG_LEVEL=info

# Database URLs (for local development)
MONGODB_URI=mongodb://admin:mongo123@localhost:27017/agent_manager?authSource=admin
REDIS_URL=redis://:redis123@localhost:6379
DATABASE_URL=postgres://postgres:postgres123@localhost:5432/orchestrator?sslmode=disable