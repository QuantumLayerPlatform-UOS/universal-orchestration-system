# QuantumLayer Platform - Environment Configuration Example

# LLM Provider Configuration
# Available providers: ollama, groq, openai, anthropic, azure
# Leave empty to auto-detect based on available credentials
LLM_PROVIDER=ollama
LLM_MODEL=mistral
LLM_TEMPERATURE=0.7
LLM_MAX_TOKENS=2000

# Ollama Configuration (Default for Development)
# Can use local Ollama or remote instance
OLLAMA_BASE_URL=https://model.gonella.co.uk
USE_OLLAMA=true

# Groq Configuration (Fast Inference)
# Get your API key from https://console.groq.com
GROQ_API_KEY=your-groq-api-key

# OpenAI Configuration
# Get your API key from https://platform.openai.com
OPENAI_API_KEY=your-openai-api-key

# Anthropic Configuration
# Get your API key from https://console.anthropic.com
ANTHROPIC_API_KEY=your-anthropic-api-key

# Azure OpenAI Configuration
# Required for production deployment
AZURE_OPENAI_API_KEY=your-azure-openai-api-key
AZURE_OPENAI_ENDPOINT=https://your-instance.openai.azure.com
AZURE_OPENAI_INSTANCE_NAME=your-instance-name
AZURE_OPENAI_DEPLOYMENT_NAME=gpt-35-turbo
AZURE_OPENAI_API_VERSION=2023-05-15

# Service Configuration
NODE_ENV=development
LOG_LEVEL=info

# Database Configuration
DB_HOST=postgres
DB_PORT=5432
DB_NAME=orchestrator
DB_USER=postgres
DB_PASSWORD=postgres123

# MongoDB Configuration
MONGO_URI=mongodb://admin:mongo123@mongodb:27017/agent_manager?authSource=admin

# Redis Configuration
REDIS_HOST=redis
REDIS_PORT=6379
REDIS_PASSWORD=redis123

# Temporal Configuration
TEMPORAL_HOST_PORT=temporal:7233

# Service URLs (for development)
ORCHESTRATOR_URL=http://localhost:8080
INTENT_PROCESSOR_URL=http://localhost:8081
AGENT_MANAGER_URL=http://localhost:8082